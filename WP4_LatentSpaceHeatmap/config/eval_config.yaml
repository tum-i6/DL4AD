# MODEL PROPERTIES
model_name: MaskRCNN-ResNet50-IS       # Name of the detection model, which should be trained. See the list at the bottom of this page for all the supported models.
pretrained_weights_path: /path/to/weights.pth # Path to a model weights file, which should be used for fine-tuning the detector.

# DATASET PARAMETERS
dataset: CityPersons # EuroCityPersons  # KIA  # CityPersons  # Name of the dataset, which should be used for training. Options: KIA or CityPersons.
data_path: /path/to/CityPersons

# PEDESTRIAN HYPERPARAMETERS
min_obj_pixels: 30  # CP:50, training  # CP, KIA: 1  # Filter out all pedestrian instances (during training) that have a lower amount of visible instance pixels than here specified. Must be an integer number greater or equal to zero. Used to filter out small or heavily occluded pedestrians with a too low amount of visible instance pixels. Set this to 1 to include all visible pedestrian instances during training.
max_occl: 0.95  # CP: 0.95  training#  CP,KIA: 0.99  # Filter out all pedestrian instances (during training) that have a higher occlusion rate than here specified. Must be a float number between 0 and 1.0. Higher values mean that samples with higher occlusions are included during training. Set this to 0.99 to include all visible pedestrian instances during training (1.0 means fully occluded and not visible at all).
max_distance: 75 # CP: 75 training # KIA: 100  # CP: 500  # Filter out all pedestrian instances (during training) that have a higher distance than here specified. Must be an integer number greater or equal to zero, that specifies the distance in meters. Set this to 100 to include all pedestrian instances during training for the KIA dataset (100 meters is the highest annotated distance value).

# GPU SETTINGS
gpu_id: '3'  # The integer ID of the GPU, which should be used for training. Only single-GPU training currently supported.
num_workers: 2  # Amount of sub-processes for loading the data.

# TRAINING HYPERPARAMETERS
batch_size: 1  # 4  # Amount of training images per batch.
seed: 1  # Seed for the random module (used for reproducibility).

# SUPPORTED MODELS
# Naming syntax for every model: {architecture name}-{backbone name}-{task}.

# List of plain object detection (OD) models:
# FasterRCNN-ResNet50-OD       -> two-stage detector
# FCOS-ResNet50-OD             -> one-stage detector
# RetinaNet-ResNet50-OD        -> one-stage detector
# SSD300-ResNet50-OD           -> one-stage detector

# List of object detection models that support keypoint detection (KD):
# KeypointRCNN-ResNet50-KD     -> two-stage detector

# List of object detection models that support instance segmentation (IS):
# MaskRCNN-ResNet50-IS         -> two-stage detector

# Boosting Scores
b: 4.5 #alpha
c: 0.2 #beta
bias: 0.09

mode: 'boosted'   # boosted, normal
# evaluation
conf_threshold: 0.5